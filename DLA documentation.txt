Diffusion-limited aggregation:
Have a 2d box. Somewhere in the box, there is at least one particle in a fixed position. Release a particle into the box, and have it move around in a pre-defined manner. When the particle is adjacent to one of the other particles in the box, said particle stops moving. Release another particle and begin again. After sufficient iterations, the particles seem to form a tree-like structure.
There are multiple different ways to adjust this. One particle at the centre of the box, a row of particles at the bottom of the box, or more. A two-dimensional box, three dimensional cube, four dimensional tesseract or higher (a 1d line is too trivial for interesting structures to form). A circle, the sirface of a cylinder (looping in one axis), surface of a torus (looping in both axes), a hexagon, or more. Two different types of particles, that can stick to their own type but not the other type. Have the chance of sticking be less than 1 (but greater than 0). Have each direction the particles can move be equal, or bias the directions. 

My version
My version differs from the standard model, in some ways

In my version, I have a 2d matrix, with initially a row of particles on the bottom. There is no loop, so I have a rectangle as opposed to the surface of a cylinder or torus. I chose to avoid looping because I did not believe it would be useful. Only one type of particle. All that is standard.
The problem with doing a standard DLA is that the time for a particle to stick is random. It could head to the nearest particle instantly, or wander around for an indeterminate amount of time. As such, I felt it may be faster to use a method that would give results in a fixed amount of time (assuming fixed time per matrix multiplication)

Method: instead of having one particle, simulate a large amount, with the top constantly being restocked. allow unstickiness; i.e. allow the particles to leave when they are adjacent to a fixed particle. Every 
Method: instead of having one particle per box, having a varying amount of virtual particles in each box, with the top row constantly being restocked, and being set to 1 every step. allow unstickiness; i.e. allow the particles to leave when they are adjacent to a fixed particle. To prevent the box from eventually having a value of 1 everywhere, I have absorbtion with particles adjacent to filled in boxes. Every few iterations, I select a virtual particle at random, and fill in the box it is in.
The amount of 'virtual particles' is large enough that it can be modelled as a heat equation. A solution to a 2d heat equation with varying internal densities over time is beyond my mathematical ability to calculate analytically (and I don't know if an analytical solution is even possible under those conditions). However, a computational approximation is within my computational abilities.

At each step per box in the matrix, have a certain amount of the particles in the box (num-particles times kappa) move to each each adjacent non-filled box. The amount is removed from the box, and added to the adjacent box. If an adjacent box is filled, (num-particles times kappa times absorbtion-rate) is removed from the box, but nothing is added to the filled box.
After a fixed number of steps, go through all the boxes adjacent to the filled-in cells, and select one of them at random proportionate to the number of particles in the box (e.g. if the only adjacent boxes have values [0.1, 0.8, 0.1], the middle box has an 80 percent chance of being selected, while the other boxes have a ten percent chance each.). Note that when a box is filled in, the other boxes are not cleared of particles.
This is essentially a finite difference approximation
Set kappa (or h) to a small number. As of time of writing, kappa is 1/100. the number of steps per fill-in is max(1/kappa, height)*3
If number of steps is too small, the item above the previuosly selected item has a vastly higher chance of being selected than any other item, leading to pillars instead of the expected trees. 
If kappa is too large, the calculations become unstable, and fail to approximate a physical analogue close enough to accuracy (by definitions of euler method and differentiation, it becomes more accurate as kappa approaches 0, and less accurate as kappa leaves 0)
Therefore, we should have kappa be as close to 0 as possible. Unfortunately, there are issues with this plan. As kappa (a fraction of unit time) becomes smaller, timesteps per unit time increases, and the time taken per simulation increases. Additionally, computers experience instability when kappa gets too small, leading to rounding errors. The value of kappa in current versions looks to be much larger than the cut-off point (denoted as epsilon. On numpy's 64 bit floating point numbers, epsilon is 2^-26), where accuracy problems caused by too large kappa are outweighed by rounding errors, but I'm not sure that's the case. For step $n$, where n < height, the value of the n'th item is kappa^n. With kappa = 1/100, the nth cell at step n is less than epsilon when n is greater thsn or equal to 8. Since I tend to have heights be in the 20's or in the hundreds, this is a problem, but increasing kappa isn't a good option, especially since it isn't very helpful (e.g. kappa at 1/10 will reach the problem point at cieling(n)=16, and an absurdly large kappa = 1/2 will reach this point at n=26)  I have decided to, at the start of the iteration, set each cell to epsilon, so as to ensure that the cells won't decrease below epsilon (barring absorbtion, but incoming particles will most likely outweigh that before serious problems ensue). I'm not entirely sure if this is a good idea, though.

Maybe make kappa 2^-m (e.g. 1/64)

animated plot: due to differences in plot implementations, gives result upside down